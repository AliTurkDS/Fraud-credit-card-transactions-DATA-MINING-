{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fraud Detection\n\nIn this project, we'll be building a classification model that aims to detect fraud in credit card transactions. This type of task usually deals with extremely imbalanced datasets, so we'll also be looking into dealing with those. Without further ado, let's check out our dataset.","metadata":{}},{"cell_type":"code","source":"#import modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:47.504504Z","iopub.execute_input":"2023-01-20T15:12:47.505143Z","iopub.status.idle":"2023-01-20T15:12:48.330768Z","shell.execute_reply.started":"2023-01-20T15:12:47.505016Z","shell.execute_reply":"2023-01-20T15:12:48.329467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit_card = pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")\ncredit_card.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:48.333805Z","iopub.execute_input":"2023-01-20T15:12:48.334407Z","iopub.status.idle":"2023-01-20T15:12:54.813865Z","shell.execute_reply.started":"2023-01-20T15:12:48.334332Z","shell.execute_reply":"2023-01-20T15:12:54.812457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset that we have today consists of 31 variables, including our target variable: Class. 0 represents not fraud and 1 represents fraud. The remaining variables consist of Time, Amount and 28 V variables. The V variables are the result of a PCA (dimensionality reduction) transformation in order to protect customer information. So in this project, we wouldn't have the details to present a very interpretable result. Rather, we'll focus on the methods and evaluations we can adopt to deal with imbalanced datasets.","metadata":{}},{"cell_type":"code","source":"credit_card.describe()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:54.815525Z","iopub.execute_input":"2023-01-20T15:12:54.815957Z","iopub.status.idle":"2023-01-20T15:12:55.452137Z","shell.execute_reply.started":"2023-01-20T15:12:54.815916Z","shell.execute_reply":"2023-01-20T15:12:55.450737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that only Time and Amount have drastically different scales from the other variables. We'll have to scale them later.","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"First, let's perform a simple EDA on our dataset.","metadata":{}},{"cell_type":"markdown","source":"**Target Variable: Class**","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=credit_card[\"Class\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:55.455716Z","iopub.execute_input":"2023-01-20T15:12:55.457194Z","iopub.status.idle":"2023-01-20T15:12:55.742643Z","shell.execute_reply.started":"2023-01-20T15:12:55.457128Z","shell.execute_reply":"2023-01-20T15:12:55.740932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit_card[\"Class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:55.744131Z","iopub.execute_input":"2023-01-20T15:12:55.744569Z","iopub.status.idle":"2023-01-20T15:12:55.75854Z","shell.execute_reply.started":"2023-01-20T15:12:55.744522Z","shell.execute_reply":"2023-01-20T15:12:55.756859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the extreme imbalance between the two classes of our target variable. This dataset is an accurate reflection of real-world dataset. Obviously, most credit card transactions are not going to be fraud.","metadata":{}},{"cell_type":"markdown","source":"**Time and Amount**","metadata":{}},{"cell_type":"code","source":"sns.histplot(data=credit_card, x=\"Time\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:55.760542Z","iopub.execute_input":"2023-01-20T15:12:55.760959Z","iopub.status.idle":"2023-01-20T15:12:56.331882Z","shell.execute_reply.started":"2023-01-20T15:12:55.760923Z","shell.execute_reply":"2023-01-20T15:12:56.330269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data=credit_card, x=\"Amount\", bins=500)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:56.333542Z","iopub.execute_input":"2023-01-20T15:12:56.334448Z","iopub.status.idle":"2023-01-20T15:12:57.685969Z","shell.execute_reply.started":"2023-01-20T15:12:56.334284Z","shell.execute_reply":"2023-01-20T15:12:57.684445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also see that variables Time and Amount have odd distributions. Amount is especially skewed, so it's important that we transform them later.","metadata":{}},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"markdown","source":"But first, let's split the data into training and testing before we do anything else.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:57.687862Z","iopub.execute_input":"2023-01-20T15:12:57.688289Z","iopub.status.idle":"2023-01-20T15:12:57.824574Z","shell.execute_reply.started":"2023-01-20T15:12:57.68825Z","shell.execute_reply":"2023-01-20T15:12:57.822899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = credit_card.Class\nX = credit_card.drop('Class', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:57.826205Z","iopub.execute_input":"2023-01-20T15:12:57.826695Z","iopub.status.idle":"2023-01-20T15:12:57.875264Z","shell.execute_reply.started":"2023-01-20T15:12:57.826654Z","shell.execute_reply":"2023-01-20T15:12:57.873501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split so that the proportions of imbalance remains the same in the training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:57.880811Z","iopub.execute_input":"2023-01-20T15:12:57.882636Z","iopub.status.idle":"2023-01-20T15:12:58.178427Z","shell.execute_reply.started":"2023-01-20T15:12:57.882575Z","shell.execute_reply":"2023-01-20T15:12:58.176771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll split the training and testing dataset such that the proportions of class 1 and class 0 are the same in both the training and testing dataset.","metadata":{}},{"cell_type":"code","source":"#training dataset proportion\ny_train.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:58.180025Z","iopub.execute_input":"2023-01-20T15:12:58.181072Z","iopub.status.idle":"2023-01-20T15:12:58.195596Z","shell.execute_reply.started":"2023-01-20T15:12:58.181023Z","shell.execute_reply":"2023-01-20T15:12:58.19343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing dataset proportion\ny_test.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:58.197963Z","iopub.execute_input":"2023-01-20T15:12:58.198792Z","iopub.status.idle":"2023-01-20T15:12:58.211433Z","shell.execute_reply.started":"2023-01-20T15:12:58.198742Z","shell.execute_reply":"2023-01-20T15:12:58.209903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\nNext, we'll be scaling Time and Amount. We'll be using the PowerTransfomer to help us automatically scale and normalize the two variables","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:58.213759Z","iopub.execute_input":"2023-01-20T15:12:58.214311Z","iopub.status.idle":"2023-01-20T15:12:58.222985Z","shell.execute_reply.started":"2023-01-20T15:12:58.214269Z","shell.execute_reply":"2023-01-20T15:12:58.221484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#instantiate power transformer\npt_amount = PowerTransformer()\n\n#transform amount \nX_train['Amount_scaled'] = pt_amount.fit_transform(X_train['Amount'].values.reshape(-1,1))\nsns.histplot(data=X_train, x=\"Amount_scaled\", bins=100)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:58.225177Z","iopub.execute_input":"2023-01-20T15:12:58.225771Z","iopub.status.idle":"2023-01-20T15:12:59.160801Z","shell.execute_reply.started":"2023-01-20T15:12:58.225711Z","shell.execute_reply":"2023-01-20T15:12:59.1591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#instantiate power transformer\npt_time = PowerTransformer()\n\n#transform time\nX_train['Time_scaled'] = pt_time.fit_transform(X_train['Time'].values.reshape(-1,1))\nsns.histplot(data=X_train, x=\"Time_scaled\", bins=100)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:12:59.162704Z","iopub.execute_input":"2023-01-20T15:12:59.164022Z","iopub.status.idle":"2023-01-20T15:13:00.209381Z","shell.execute_reply.started":"2023-01-20T15:12:59.163964Z","shell.execute_reply":"2023-01-20T15:13:00.20815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop origianl time and amount\nX_train = X_train.drop(['Time', 'Amount'], axis=1)\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:00.211629Z","iopub.execute_input":"2023-01-20T15:13:00.212703Z","iopub.status.idle":"2023-01-20T15:13:00.343987Z","shell.execute_reply.started":"2023-01-20T15:13:00.212644Z","shell.execute_reply":"2023-01-20T15:13:00.342567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Apply transformation to testing data**\n\nPerfect, then we apply the PowerTransformer to our testing dataset as well. (The reason we do this seperately is to prevent data leakage)","metadata":{}},{"cell_type":"code","source":"#transform Amount and Time for testing data\nX_test['Amount_scaled'] = pt_amount.transform(X_test['Amount'].values.reshape(-1,1))\nX_test['Time_scaled'] = pt_time.transform(X_test['Time'].values.reshape(-1,1))\n\nX_test = X_test.drop(['Time', 'Amount'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:00.345852Z","iopub.execute_input":"2023-01-20T15:13:00.346409Z","iopub.status.idle":"2023-01-20T15:13:00.413489Z","shell.execute_reply.started":"2023-01-20T15:13:00.346338Z","shell.execute_reply":"2023-01-20T15:13:00.412055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perfect! Now that we've performed some basic data preprocessing, let's move on to experiment with different methods of dealing with imbalanced data.","metadata":{}},{"cell_type":"markdown","source":"# Imbalanced Data\n\nImbalanced datasets are a pain to deal with, but some models intrinsically perform better with imbalanced data than others. Typically tree-based and boosting algorithms perform better with imbalanced data. Boosting models are especially ideal as higher weight is given to the minority class at each iteration. We'll see how they perform.\n\n**Good for Imbalanced Dataset**\n- Decision Tree\n- Random Forest\n- Adaboost\n- Gradient Boosting\n\n**Bad for Imbalanced Dataset**\n- Logistics Regression\n- Support Vector Classifier\n- Naives Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, f1_score","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:00.415097Z","iopub.execute_input":"2023-01-20T15:13:00.41559Z","iopub.status.idle":"2023-01-20T15:13:00.667678Z","shell.execute_reply.started":"2023-01-20T15:13:00.415547Z","shell.execute_reply":"2023-01-20T15:13:00.666181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start by building a logistic regression model as our baseline model.","metadata":{}},{"cell_type":"code","source":"#build logistics regression model\nlog_reg = LogisticRegression()\n\nlog_reg.fit(X_train, y_train)\ny_pred = log_reg.predict(X_test)\n\nlog_reg_accuracy = accuracy_score(y_test, y_pred)\nprint(\"Logistics Regression Accuracy: \", log_reg_accuracy)\n\n#create confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #ftm='g' to disable scientific notation\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:00.66934Z","iopub.execute_input":"2023-01-20T15:13:00.671132Z","iopub.status.idle":"2023-01-20T15:13:05.239932Z","shell.execute_reply.started":"2023-01-20T15:13:00.671073Z","shell.execute_reply":"2023-01-20T15:13:05.238643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we were to look at accuracy as our evaluating metric, we can see that logistic regression performed extraordinarily well at 99.9%. But this is often the flaw with imbalanced dataset. Even if the classification model classifies everything as the majority class, the model would achieve high accuracy. So when dealing with imbalanced dataset, we have to look at other metrics. In most cases, we prefer to look at the F-1 score, which is the harmonic mean between precision and recall.","metadata":{}},{"cell_type":"code","source":"#print classification report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:05.241737Z","iopub.execute_input":"2023-01-20T15:13:05.242178Z","iopub.status.idle":"2023-01-20T15:13:05.404498Z","shell.execute_reply.started":"2023-01-20T15:13:05.242142Z","shell.execute_reply":"2023-01-20T15:13:05.402785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the confusion matrix and classification report above, we can see that the logistics regression model achieved a precision of 0.86 and a recall of 0.62 for class 1. This means that while 86% of its fraud predictions were correct, it only captured 62% of the fraud transactions. In real-life, this recall may be too low. Our primary objective is to identify as much fraud transactions as possible.","metadata":{}},{"cell_type":"markdown","source":"# Precision-Recall Tradeoff\n\nTo identify more fraud transactions, what we could do is we could adjust the decision threshold for logistics regression. Eeach sample is assigned a probability (of it being fraud) by the logistic regression model. The decisive threshold is, by default, 0.5. We can lower that threshold so that more samples are predicted as fraud (therefore capable of capturing more actual frauds).","metadata":{}},{"cell_type":"code","source":"#change threshold to 0.2\ny_pred_new = (log_reg.predict_proba(X_test)[:,1]>=0.2).astype(int)\n\n#build confusion matrix\ncm = confusion_matrix(y_test, y_pred_new)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax); \n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:05.406394Z","iopub.execute_input":"2023-01-20T15:13:05.407909Z","iopub.status.idle":"2023-01-20T15:13:05.723191Z","shell.execute_reply.started":"2023-01-20T15:13:05.407858Z","shell.execute_reply":"2023-01-20T15:13:05.721672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_new))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:05.724846Z","iopub.execute_input":"2023-01-20T15:13:05.725273Z","iopub.status.idle":"2023-01-20T15:13:05.886692Z","shell.execute_reply.started":"2023-01-20T15:13:05.725236Z","shell.execute_reply":"2023-01-20T15:13:05.885163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, by lowering the decision threshold to 0.2, we were able to increase our recall from 0.62 to 0.71, meaning we were able to capture an additional 9% of fraud transactions. This achievement, however, does not come without a cost. As we tried to predict more transactions as fraud, we also misclassified more non-fraud transactions as fraud, decreasing the precision (0.86 -> 0.79). Thus, we can observe a trade-off relationship between precision and recall.\n\nWe don't want either one of the value (precision and recall) to be too low, so we must strive for a balance between the two. Thankfully, that is exactly what F-1 score is designed to do. The F-1 score is the harmonic mean between recall and precision. So from now on, we will use F1-score as our main evaluation metric.\n\nIn the example of logistic regression, the F-1 score for a threshold=0.2 is greater than that of the default threshold (0.5). Therefore, if we were to use logistic regression as our model, it will be better to set the threshold around 0.2.","metadata":{}},{"cell_type":"markdown","source":"# RandomForest\n\nNext, let's try using a model that is intrinisically better at dealing with imbalanced datasets. We'll start with RandomForest.","metadata":{}},{"cell_type":"code","source":"#build randomforest model\nrfm = RandomForestClassifier(random_state=42)\n\nrfm.fit(X_train, y_train)\nrfm_pred = rfm.predict(X_test)\n\n#build confusion matrix\nrfm_cm = confusion_matrix(y_test, rfm_pred)\n\nax= plt.subplot()\nsns.heatmap(rfm_cm, annot=True, fmt='g', ax=ax);\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:13:05.888527Z","iopub.execute_input":"2023-01-20T15:13:05.889065Z","iopub.status.idle":"2023-01-20T15:17:49.211491Z","shell.execute_reply.started":"2023-01-20T15:13:05.889014Z","shell.execute_reply":"2023-01-20T15:17:49.210289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, rfm_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:17:49.213834Z","iopub.execute_input":"2023-01-20T15:17:49.214706Z","iopub.status.idle":"2023-01-20T15:17:49.368363Z","shell.execute_reply.started":"2023-01-20T15:17:49.214649Z","shell.execute_reply":"2023-01-20T15:17:49.367051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! We can see that RandomForest performed much better than logistics regression! The F-1 score is much higher. Also note that this model is being built without any tuning and addresses to the imbalanced target variable yet.","metadata":{}},{"cell_type":"markdown","source":"# Adaboost\n\nNext, let's try adaboost.","metadata":{}},{"cell_type":"code","source":"#build adaboost classifier\nada = AdaBoostClassifier(random_state=42)\n\nada.fit(X_train, y_train)\nada_pred = ada.predict(X_test)\n\n#build confusion matrix\nada_cm = confusion_matrix(y_test, ada_pred)\n\nax= plt.subplot()\nsns.heatmap(ada_cm, annot=True, fmt='g', ax=ax);\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:17:49.370569Z","iopub.execute_input":"2023-01-20T15:17:49.371484Z","iopub.status.idle":"2023-01-20T15:19:04.353052Z","shell.execute_reply.started":"2023-01-20T15:17:49.37143Z","shell.execute_reply":"2023-01-20T15:19:04.351728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, ada_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:19:04.35512Z","iopub.execute_input":"2023-01-20T15:19:04.355812Z","iopub.status.idle":"2023-01-20T15:19:04.51618Z","shell.execute_reply.started":"2023-01-20T15:19:04.355705Z","shell.execute_reply":"2023-01-20T15:19:04.514933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turns out Adaboost didn't perform very well in this particular case. We probably could improve the model's performance by tuning and playing around with the parameters, but RandomForest seems to be the better choice here.","metadata":{}},{"cell_type":"markdown","source":"# Gradient Boosting","metadata":{}},{"cell_type":"code","source":"#build gradient boosting\ngb = GradientBoostingClassifier(random_state=42)\n\ngb.fit(X_train, y_train)\ngb_pred = gb.predict(X_test)\n\n#build confusion matrix\ngb_cm = confusion_matrix(y_test, gb_pred)\n\nax= plt.subplot()\nsns.heatmap(gb_cm, annot=True, fmt='g', ax=ax);\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:19:04.517978Z","iopub.execute_input":"2023-01-20T15:19:04.519146Z","iopub.status.idle":"2023-01-20T15:24:39.856809Z","shell.execute_reply.started":"2023-01-20T15:19:04.519092Z","shell.execute_reply":"2023-01-20T15:24:39.855408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, gb_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:39.862942Z","iopub.execute_input":"2023-01-20T15:24:39.863431Z","iopub.status.idle":"2023-01-20T15:24:40.01591Z","shell.execute_reply.started":"2023-01-20T15:24:39.863395Z","shell.execute_reply":"2023-01-20T15:24:40.014632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! GradientBoosting actually performed horribly! We can see that the F-1 score is super low. It almost feels like it's not predicting any fraud transactions at all. Let's just resort to using RandomForest.","metadata":{}},{"cell_type":"markdown","source":"# Oversampling, Undersampling, SMOTE\n\nNow, let's move on to dealing with imbalanced data. The three most popular ways to treat imbalanced data is oversampling, undersampling and SMOTE. We will demonstrate and try all three to compare which method works out the best in this scenario.","metadata":{}},{"cell_type":"markdown","source":"> When we resample our data, remember it's important that you only resample the training data and not the testing data. Build your model using the resampled data and then test it with the untouched testing data.","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.018541Z","iopub.execute_input":"2023-01-20T15:24:40.019472Z","iopub.status.idle":"2023-01-20T15:24:40.024876Z","shell.execute_reply.started":"2023-01-20T15:24:40.019428Z","shell.execute_reply":"2023-01-20T15:24:40.023631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#double check the counts of 0 and 1s\ny_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.026478Z","iopub.execute_input":"2023-01-20T15:24:40.027008Z","iopub.status.idle":"2023-01-20T15:24:40.043158Z","shell.execute_reply.started":"2023-01-20T15:24:40.026967Z","shell.execute_reply":"2023-01-20T15:24:40.042111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concatenate our training data back together\nX_concat = pd.concat([X_train, y_train], axis=1)\n\n# separate minority and majority classes\nnot_fraud = X_concat[X_concat.Class==0]\nfraud = X_concat[X_concat.Class==1]","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.044643Z","iopub.execute_input":"2023-01-20T15:24:40.045251Z","iopub.status.idle":"2023-01-20T15:24:40.134807Z","shell.execute_reply.started":"2023-01-20T15:24:40.045212Z","shell.execute_reply":"2023-01-20T15:24:40.133429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Oversampling**","metadata":{}},{"cell_type":"code","source":"# oversample fraud transaction (minority)\nfraud_oversampled = resample(fraud, replace=True, n_samples=len(not_fraud), random_state=42) # with replacement\n\n# combine majority and oversampled minority\noversampled = pd.concat([not_fraud, fraud_oversampled])\n\n#split X and y\ny_train_oversampled = oversampled.Class\nX_train_oversampled = oversampled.drop('Class', axis=1)\n\n# check new class counts\noversampled.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.136512Z","iopub.execute_input":"2023-01-20T15:24:40.137025Z","iopub.status.idle":"2023-01-20T15:24:40.30289Z","shell.execute_reply.started":"2023-01-20T15:24:40.136976Z","shell.execute_reply":"2023-01-20T15:24:40.30141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Undersampling**","metadata":{}},{"cell_type":"code","source":"# undersample not fraud (majority)\nnot_fraud_undersampled = resample(not_fraud, replace=False, n_samples=len(fraud), random_state=42) #without replacement\n\n# combine undersampled majority and minority\nundersampled = pd.concat([not_fraud_undersampled, fraud])\n\n#split X and y\ny_train_undersampled = undersampled.Class\nX_train_undersampled = undersampled.drop('Class', axis=1)\n\n# check new class counts\nundersampled.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.304702Z","iopub.execute_input":"2023-01-20T15:24:40.305168Z","iopub.status.idle":"2023-01-20T15:24:40.325724Z","shell.execute_reply.started":"2023-01-20T15:24:40.30513Z","shell.execute_reply":"2023-01-20T15:24:40.324515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SMOTE**","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\n\nX_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n\ny_train_sm.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.327466Z","iopub.execute_input":"2023-01-20T15:24:40.328311Z","iopub.status.idle":"2023-01-20T15:24:40.97384Z","shell.execute_reply.started":"2023-01-20T15:24:40.328253Z","shell.execute_reply":"2023-01-20T15:24:40.972308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Oversampling\n\nNow that we have equalized the imbalanced ratio of our target variable, we'll try RandomForest again to see if we can observe an improvement.","metadata":{}},{"cell_type":"code","source":"#RFM with oversampled data\nrfm_OS = RandomForestClassifier(random_state=42)\n\nrfm_OS.fit(X_train_oversampled, y_train_oversampled)\nrfm_OS_pred = rfm_OS.predict(X_test)\n\n#build confusion matrix\nrfm_OS_cm = confusion_matrix(y_test, rfm_OS_pred)\n\nax= plt.subplot()\nsns.heatmap(rfm_OS_cm, annot=True, fmt='g', ax=ax); \n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:24:40.97605Z","iopub.execute_input":"2023-01-20T15:24:40.976629Z","iopub.status.idle":"2023-01-20T15:28:15.060394Z","shell.execute_reply.started":"2023-01-20T15:24:40.976573Z","shell.execute_reply":"2023-01-20T15:28:15.058955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, rfm_OS_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:28:15.06194Z","iopub.execute_input":"2023-01-20T15:28:15.062464Z","iopub.status.idle":"2023-01-20T15:28:15.223006Z","shell.execute_reply.started":"2023-01-20T15:28:15.062424Z","shell.execute_reply":"2023-01-20T15:28:15.221633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on F-1 score, training RF on an oversampled data does not exceed the performance of the initial RF model. ","metadata":{}},{"cell_type":"markdown","source":"# Undersampling","metadata":{}},{"cell_type":"code","source":"#RFM with undersampled data\nrfm_US = RandomForestClassifier(random_state=42)\n\nrfm_US.fit(X_train_undersampled, y_train_undersampled)\nrfm_US_pred = rfm_US.predict(X_test)\n\n#build confusion matrix\nrfm_US_cm = confusion_matrix(y_test, rfm_US_pred)\n\nax= plt.subplot()\nsns.heatmap(rfm_US_cm, annot=True, fmt='g', ax=ax);\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:28:15.224453Z","iopub.execute_input":"2023-01-20T15:28:15.224867Z","iopub.status.idle":"2023-01-20T15:28:16.580074Z","shell.execute_reply.started":"2023-01-20T15:28:15.224833Z","shell.execute_reply":"2023-01-20T15:28:16.579113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, rfm_US_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:28:16.581703Z","iopub.execute_input":"2023-01-20T15:28:16.582942Z","iopub.status.idle":"2023-01-20T15:28:16.748281Z","shell.execute_reply.started":"2023-01-20T15:28:16.582884Z","shell.execute_reply":"2023-01-20T15:28:16.747078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Undersampling seems to do even worse than oversampling. We can see that precision dropped to 0.05 in exchange for a relatively high recall at 0.90. This leads to a low f1-score. Although we were able to identify 90% of the fraud transactions, the predictions are not precise at all.","metadata":{}},{"cell_type":"markdown","source":"# SMOTE","metadata":{}},{"cell_type":"code","source":"#RFM with SMOTE\nrfm_sm = RandomForestClassifier(random_state=42)\n\nrfm_sm.fit(X_train_sm, y_train_sm)\nrfm_sm_pred = rfm_sm.predict(X_test)\n\n#build confusion matrix\nrfm_sm_cm = confusion_matrix(y_test, rfm_sm_pred)\n\nax= plt.subplot()\nsns.heatmap(rfm_sm_cm, annot=True, fmt='g', ax=ax);\n\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Not Fraud', 'Fraud']); ax.yaxis.set_ticklabels(['Not Fraud', 'Fraud']);","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:28:16.749835Z","iopub.execute_input":"2023-01-20T15:28:16.750222Z","iopub.status.idle":"2023-01-20T15:36:07.077802Z","shell.execute_reply.started":"2023-01-20T15:28:16.750186Z","shell.execute_reply":"2023-01-20T15:36:07.076461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, rfm_sm_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:36:07.079482Z","iopub.execute_input":"2023-01-20T15:36:07.079919Z","iopub.status.idle":"2023-01-20T15:36:07.239458Z","shell.execute_reply.started":"2023-01-20T15:36:07.079881Z","shell.execute_reply":"2023-01-20T15:36:07.238145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results from SMOTE is also pretty good. Although the F-1 score was not as high as the initial RF model, the recall is higher. In turn, the precision is still within acceptable range, so not too bad.","metadata":{}},{"cell_type":"markdown","source":"# Model Comparison\n\nFinally, let's put everything together to compare the different statistics of the four RFM that we built.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\n#model dictionary\npredicted_values = {\"RandomForest\": rfm_pred, \"RandomForest OS\": rfm_OS_pred, \"RandomForest US\": rfm_US_pred, \"RandomForest SMOTE\": rfm_sm_pred}\n\n#create df\ndf = pd.DataFrame(columns=['model', 'precision', 'recall', 'f1_score'])\n\n#plug precision recall and f1score into the dataframe for each model\nfor key, value in predicted_values.items():\n    precision = precision_recall_fscore_support(y_test, value, average=None)[0][1]\n    recall = precision_recall_fscore_support(y_test, value, average=None)[1][1]\n    f1_score = precision_recall_fscore_support(y_test, value, average=None)[2][1]\n    df = df.append({'model': key, 'precision':precision, 'recall':recall, 'f1_score':f1_score}, ignore_index=True)\n\ndf = df.set_index('model')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:36:07.241095Z","iopub.execute_input":"2023-01-20T15:36:07.241532Z","iopub.status.idle":"2023-01-20T15:36:07.68595Z","shell.execute_reply.started":"2023-01-20T15:36:07.241494Z","shell.execute_reply":"2023-01-20T15:36:07.684902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, we can see that the f1_score is the highest for the initial RandomForest model (without any treatments to the imbalanced dataset). The first model, however, has a relatively higher precision than its recall. In many cases of imbalanced dataset (like this with fraud detection), we should be willing to sacrifice some precision for better recall. Therefore, RandomForest with SMOTE also seems like a pretty good choice. RandomForest US would be way too extreme as it sacrificed way too much precision for a little increase in recall.","metadata":{}},{"cell_type":"markdown","source":"# ROC and AUC\n\nFinally, let's take a look at another evaluation metric ROC and AUC, and see if we can extract some insights.","metadata":{}},{"cell_type":"code","source":"#change figure size\nplt.figure(figsize=(10, 10))\n\n# RFM SMOTE\nrfm_sm_probas = rfm_sm.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, rfm_sm_probas)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, 'b', linewidth=3, label = 'SMOTE AUC = %0.4f' % roc_auc)\n\n#RFM Undersampled\nrfm_US_probas = rfm_US.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, rfm_US_probas)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, 'g', linewidth=3, label = 'US AUC = %0.4f' % roc_auc)\n\n#RFM Oversampled\nrfm_OS_probas = rfm_OS.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, rfm_OS_probas)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, 'r', linewidth=3, label = 'OS AUC = %0.4f' % roc_auc)\n\n#RFM\nrfm_probas = rfm.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, rfm_probas)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, 'purple', linewidth=3, label = 'Nth AUC = %0.4f' % roc_auc)\n\n#plot horizontal line at y=0.9 and y=0.99\nplt.axhline(y=0.9, color = 'black', linestyle='dashed', linewidth=3)\nplt.axhline(y=0.99, color = 'black', linestyle='dashed', linewidth=3)\n\nplt.title('RFM Receiver Operating Characteristic')\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:36:07.687486Z","iopub.execute_input":"2023-01-20T15:36:07.688608Z","iopub.status.idle":"2023-01-20T15:36:12.347301Z","shell.execute_reply.started":"2023-01-20T15:36:07.688571Z","shell.execute_reply":"2023-01-20T15:36:12.345815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the comparison of the ROC curves for the four different models. For those who always gets confused by TPR and FPR (confusing terms) like I do, let's give it a quick review:\n\n* True Positive Rate (sensitivity): Out of all fraud cases, the amount that is classified as fraud\n* False Positive Rate (1-specificity): Out of all non-fraud cases, the amount that is classified as fraud","metadata":{}},{"cell_type":"markdown","source":"> Again, we have a trade-off relationship between the two. Which model is better ultimately comes down to what is the minimum TPR that you're willing to accept. We can see that if we can accept a TPR of 0.9 (90% of all fraud captured), then RF with SMOTE may be best because it achieves that TPR with the lowest FPR (bottom dashed horizontal line). But if we want to achieve a TPR of 0.99 (99% of all fraud captured), then RF with Undersampling is the best. (top dashed horizontal line)","metadata":{}},{"cell_type":"markdown","source":"But be aware that in the case of an imbalanced dataset, even a false positive rate of just 0.2 means a very low precision. This is due to the extreme difference in the majority and minority class. We can see this being the case for RF with Undersampling.\n\n![image.png](attachment:91b7969f-f444-47ba-b97c-012ba8494125.png)\n\nThe FPR is only 0.03 here (2555/(91170+2555), but we can see that the precision dropped significantly. A small portion of the majority class could still be huge when compared to the minority class.","metadata":{},"attachments":{"91b7969f-f444-47ba-b97c-012ba8494125.png":{"image/png":"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"}}}]}